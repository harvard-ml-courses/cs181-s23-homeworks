{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework 2\n",
    "\n",
    "**The following notebook is meant to help you work through Problems 1 and 3 on Homework 2. You are by no means required to use it, nor are you required to fill out/use any of the boilerplate code/functions. You are welcome to implement the functions however you wish.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as c\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.special import expit as sigmoid\n",
    "from scipy.special import softmax\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "# data for Problem 1\n",
    "t_obs, y_obs = np.genfromtxt(\"data/planet-obs.csv\", delimiter = ',').T\n",
    "t_obs = np.split(t_obs, 10)\n",
    "y_obs = np.split(y_obs.reshape(-1, 1), 10)\n",
    "\n",
    "# data for Problem 3\n",
    "data = pd.read_csv(\"data/hr.csv\")\n",
    "mapper = {\n",
    "    \"Dwarf\": 0,\n",
    "    \"Giant\": 1,\n",
    "    \"Supergiant\": 2\n",
    "}\n",
    "data['Type'] = data['Type'].map(mapper)\n",
    "\n",
    "X_stars = data[['Magnitude', 'Temperature']].values\n",
    "y_stars = data['Type'].values\n",
    "\n",
    "from T2_P1_TestCases import test_p1\n",
    "from T2_P3_TestCases import test_p3_softmax, test_p3_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 Subpart 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basis1(t):\n",
    "    return np.stack([np.ones(len(t)), t], axis=1)\n",
    "\n",
    "def basis2(t):\n",
    "    \"\"\"\n",
    "    Transform t into basis [1, t, t^2]\n",
    "\n",
    "    :param t: a 1D numpy array of values to transform. Shape is (n,)\n",
    "    :return: a 2D array in which each row corresponds to a basis transformation of\n",
    "             an input value. Shape should be (n x 3)\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    pass\n",
    "\n",
    "def basis3(t):\n",
    "    \"\"\"\n",
    "    Transform t into basis [1, t, t^2, t^3, t^4, t^5]\n",
    "\n",
    "    :param t: a numpy array of values to transform. Shape is (n,)\n",
    "    :return: a 2D array in which each row corresponds to a basis transformation of\n",
    "             an input value. Shape should be (n x 6)\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressor:\n",
    "    def __init__(self, eta, runs):\n",
    "        self.eta = eta\n",
    "        self.runs = runs\n",
    "        self.W = None\n",
    "\n",
    "    def fit(self, x, y, w_init):\n",
    "        \"\"\"\n",
    "        Optimize the weights W to minimize the negative log-likelihood by using gradient descent\n",
    "\n",
    "        :param x: a 2D numpy array of transformed feature values. Shape is (n x 2), (n x 3), or (n x 6)\n",
    "        :param y: a 2D numpy array of output values. Shape is (n x 1)\n",
    "        :param w_init: a 2D numpy array that initializes the weights. Shape is (n x 1)\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # Keep this for the autograder\n",
    "        self.W = w_init\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Predict classification probability of transformed input x\n",
    "        \n",
    "        :param x: a 2D numpy array of transformed feature values. Shape is (n x 2), (n x 3), or (n x 6)\n",
    "        :return: a 2D numpy array of predicted probabilities given current weights. Shape should be (n x 1)\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_p1(LogisticRegressor, basis1, basis2, basis3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Functions for Problem 1, Subpart 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize prediction lines\n",
    "# Takes as input last_x, last_y, [list of models], basis function, title\n",
    "# last_x and last_y should specifically be the dataset that the last model\n",
    "# in [list of models] was trained on\n",
    "def visualize_prediction_lines(last_x, last_y, models, basis, title):\n",
    "    # Plot setup\n",
    "    green = mpatches.Patch(color='green', label='Ground truth model')\n",
    "    black = mpatches.Patch(color='black', label='Mean of learned models')\n",
    "    purple = mpatches.Patch(color='purple', label='Model learned from displayed dataset')\n",
    "    plt.legend(handles=[green, black, purple], loc='lower right')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Observed')\n",
    "    plt.axis([0, 6, -.1, 1.1]) # Plot ranges\n",
    "\n",
    "    # Plot dataset that last model in models (models[-1]) was trained on\n",
    "    cmap = c.ListedColormap(['r', 'b'])\n",
    "    plt.scatter(last_x, last_y, c=last_y, cmap=cmap, linewidths=1, edgecolors='black')\n",
    "\n",
    "    # Plot models\n",
    "    X_pred = np.linspace(0, 6, 1000)\n",
    "    X_pred_transformed = basis(X_pred)\n",
    "\n",
    "    ## Ground truth model\n",
    "    plt.plot(X_pred, np.cos(1.1*X_pred + 1) * 0.4 + 0.5, 'g', linewidth=5)\n",
    "\n",
    "    ## Individual learned logistic regressor models\n",
    "    Y_hats = []\n",
    "    for i in range(len(models)):\n",
    "        model = models[i]\n",
    "        Y_hat = model.predict(X_pred_transformed)\n",
    "        Y_hats.append(Y_hat)\n",
    "        if i < len(models) - 1:\n",
    "            plt.plot(X_pred, Y_hat, linewidth=.3)\n",
    "        else:\n",
    "            plt.plot(X_pred, Y_hat, 'purple', linewidth=3)\n",
    "\n",
    "    # Mean / expectation of learned models over all datasets\n",
    "    plt.plot(X_pred, np.mean(Y_hats, axis=0), 'k', linewidth=5)\n",
    "\n",
    "    plt.savefig(title + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may find it helpful to modify this function for Problem 1, Subpart 4,\n",
    "# but do not change the existing code--add your own variables\n",
    "def plot_results(basis, title):\n",
    "    eta = 0.001\n",
    "    runs = 10000\n",
    "\n",
    "    all_models = []\n",
    "    for i in range(10):\n",
    "        x, y = t_obs[i], y_obs[i]\n",
    "        x_transformed = basis(x)\n",
    "        model = LogisticRegressor(eta=eta, runs=runs)\n",
    "        model.fit(x_transformed, y, np.zeros((x_transformed.shape[1], 1)))\n",
    "        all_models.append(model)\n",
    "\n",
    "    visualize_prediction_lines(x, y, all_models, basis, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(basis1, 'basis1')\n",
    "plot_results(basis2, 'basis2')\n",
    "plot_results(basis3, 'basis3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegression:\n",
    "    def __init__(self, eta, lam):\n",
    "        self.eta = eta\n",
    "        self.lam = lam\n",
    "        self.W = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the weights W of softmax regression using gradient descent with L2 regularization\n",
    "        in the form (lambda/2) * norm(w)^2\n",
    "        Use the results from Problem 2 to find an expression for the gradient\n",
    "        \n",
    "        :param X: a 2D numpy array of (transformed) feature values. Shape is (n x 2)\n",
    "        :param y: a 1D numpy array of target values (Dwarf=0, Giant=1, Supergiant=2).\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # Initializing the weights (do not change!)\n",
    "        # The number of classes is 1 + (the highest numbered class)\n",
    "        num_classes = 1 + y.max()\n",
    "        num_features = X.shape[1]\n",
    "        self.W = np.ones((num_classes, num_features))\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def predict(self, X_pred):\n",
    "        \"\"\"\n",
    "        The code in this method should be removed and replaced! We included it\n",
    "        just so that the distribution code is runnable and produces a\n",
    "        (currently meaningless) visualization.\n",
    "        \n",
    "        Predict classes of points given feature values in X_pred\n",
    "        \n",
    "        :param X_pred: a 2D numpy array of (transformed) feature values. Shape is (n x 2)\n",
    "        :return: a 1D numpy array of predicted classes (Dwarf=0, Giant=1, Supergiant=2).\n",
    "                 Shape should be (n,)\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        preds = []\n",
    "        for x in X_pred:\n",
    "            z = np.cos(x ** 2).sum()\n",
    "            preds.append(1 + np.sign(z) * (np.abs(z) > 0.3))\n",
    "        return np.array(preds)\n",
    "    \n",
    "    def predict_proba(self, X_pred):\n",
    "        \"\"\"    \n",
    "        Predict classification probabilities of points given feature values in X_pred\n",
    "        \n",
    "        :param X_pred: a 2D numpy array of (transformed) feature values. Shape is (n x 2)\n",
    "        :return: a 2D numpy array of predicted class probabilities (Dwarf=index 0, Giant=index 1, Supergiant=index 2).\n",
    "                 Shape should be (n x 3)\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier:\n",
    "    def __init__(self, k):\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.K = k\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        In KNN, \"fitting\" can be as simple as storing the data, so this has been written for you.\n",
    "        If you'd like to add some preprocessing here without changing the inputs, feel free,\n",
    "        but this is completely optional.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def predict(self, X_pred):\n",
    "        \"\"\"\n",
    "        The code in this method should be removed and replaced! We included it\n",
    "        just so that the distribution code is runnable and produces a\n",
    "        (currently meaningless) visualization.\n",
    "        \n",
    "        Predict classes of points given feature values in X_pred\n",
    "        \n",
    "        :param X_pred: a 2D numpy array of (transformed) feature values. Shape is (n x 2)\n",
    "        :return: a 1D numpy array of predicted classes (Dwarf=0, Giant=1, Supergiant=2).\n",
    "                 Shape should be (n,)\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        preds = []\n",
    "        for x in X_pred:\n",
    "            z = np.cos(x ** 2).sum()\n",
    "            preds.append(1 + np.sign(z) * (np.abs(z) > 0.3))\n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(X):\n",
    "    \"\"\"\n",
    "    Transform [x_1, x_2] into basis [ln(x_1 + 10), x_2^2]\n",
    "\n",
    "    :param t: a 2D numpy array of values to transform. Shape is (n x 2)\n",
    "    :return: a 2D array in which each row corresponds to a basis transformation of\n",
    "             an input value. Shape should be (n x 2)\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Function for Problem 3, Subpart 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision boundary that a model produces\n",
    "def visualize_boundary(model, X, y, title, basis=None, width=2):\n",
    "    # Create a grid of points\n",
    "    x_min, x_max = min(X[:, 0] - width), max(X[:, 0] + width)\n",
    "    y_min, y_max = min(X[:, 1] - width), max(X[:, 1] + width)\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.arange(x_min, x_max, 0.05),\n",
    "        np.arange(y_min, y_max, 0.05)\n",
    "    )\n",
    "\n",
    "    # Flatten the grid so the values match spec for self.predict\n",
    "    xx_flat = xx.flatten()\n",
    "    yy_flat = yy.flatten()\n",
    "    X_pred = np.vstack((xx_flat, yy_flat)).T\n",
    "    \n",
    "    if basis is not None:\n",
    "        X_pred = basis(X_pred)\n",
    "\n",
    "    # Get the class predictions\n",
    "    Y_hat = model.predict(X_pred)\n",
    "    Y_hat = Y_hat.reshape((xx.shape[0], xx.shape[1]))\n",
    "\n",
    "    # Visualize them.\n",
    "    cmap = c.ListedColormap(['r', 'b', 'g'])\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Magnitude')\n",
    "    plt.ylabel('Temperature')\n",
    "    plt.pcolormesh(xx, yy, Y_hat, cmap=cmap, alpha=0.3)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap, linewidths=1,\n",
    "                edgecolors='black')\n",
    "\n",
    "    # Adding a legend and a title\n",
    "    red = mpatches.Patch(color='red', label='Dwarf')\n",
    "    blue = mpatches.Patch(color='blue', label='Giant')\n",
    "    green = mpatches.Patch(color='green', label='Supergiant')\n",
    "    plt.legend(handles=[red, blue, green])\n",
    "\n",
    "    # Saving the image to a file, and showing it as well\n",
    "    plt.savefig(title + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3, Subpart 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of fitting a model and visualizing the decision boundaries;\n",
    "# do this for each of the four models\n",
    "softmax_model = SoftmaxRegression(eta=0.001, lam=0.001)\n",
    "softmax_model.fit(X_stars, y_stars)\n",
    "visualize_boundary(model=softmax_model,\n",
    "                   X=X_stars,\n",
    "                   y=y_stars,\n",
    "                   title='softmax_regression_result',\n",
    "                   basis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your models by passing your fitted models into the functions below\n",
    "# softmax_model is an instance of class SoftmaxRegression fitted to data X_stars, y_stars\n",
    "# basis_model is an instance of class SoftmaxRegression fitted to data phi(X_stars), y_stars\n",
    "# knn1_model is an instance of class KNNClassifier with parameter k=1\n",
    "# knn5_model is an instance of class KNNClassifier with parameter k=5\n",
    "test_p3_softmax(softmax_model, basis_model)\n",
    "test_p3_knn(knn1_model, knn5_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
